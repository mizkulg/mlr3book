<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.1 Hyperparameter Tuning | mlr3 book</title>
  <meta name="description" content="3.1 Hyperparameter Tuning | mlr3 book" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="3.1 Hyperparameter Tuning | mlr3 book" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://mlr3book.mlr-org.com/" />
  <meta property="og:image" content="https://mlr3book.mlr-org.com/block.png" />
  
  <meta name="github-repo" content="mlr-org/mlr3book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.1 Hyperparameter Tuning | mlr3 book" />
  
  
  <meta name="twitter:image" content="https://mlr3book.mlr-org.com/block.png" />

<meta name="author" content="Michel Lang" />
<meta name="author" content="Patrick Schratz" />
<meta name="author" content="Martin Binder" />
<meta name="author" content="Florian Pfisterer" />
<meta name="author" content="Jakob Richter" />
<meta name="author" content="Nicholas G. Reich" />
<meta name="author" content="Bernd Bischl" />
<meta name="author" content="Marc Becker" />


<meta name="date" content="2020-10-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="180x180" href="apple-touch-icon.png" />
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="optimization.html"/>
<link rel="next" href="fs.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">mlr3 Manual <img src='https://raw.githubusercontent.com/mlr-org/mlr3/master/man/figures/logo.png' width=30 /></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Citation Info</a></li>
<li class="chapter" data-level="" data-path="quickstart.html"><a href="quickstart.html"><i class="fa fa-check"></i>Quickstart</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction and Overview</a></li>
<li class="chapter" data-level="2" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>2</b> Basics</a><ul>
<li class="chapter" data-level="2.1" data-path="r6.html"><a href="r6.html"><i class="fa fa-check"></i><b>2.1</b> Quick R6 Intro for Beginners</a></li>
<li class="chapter" data-level="2.2" data-path="tasks.html"><a href="tasks.html"><i class="fa fa-check"></i><b>2.2</b> Tasks</a><ul>
<li class="chapter" data-level="2.2.1" data-path="tasks.html"><a href="tasks.html#tasks-types"><i class="fa fa-check"></i><b>2.2.1</b> Task Types</a></li>
<li class="chapter" data-level="2.2.2" data-path="tasks.html"><a href="tasks.html#tasks-creation"><i class="fa fa-check"></i><b>2.2.2</b> Task Creation</a></li>
<li class="chapter" data-level="2.2.3" data-path="tasks.html"><a href="tasks.html#tasks-predefined"><i class="fa fa-check"></i><b>2.2.3</b> Predefined tasks</a></li>
<li class="chapter" data-level="2.2.4" data-path="tasks.html"><a href="tasks.html#tasks-api"><i class="fa fa-check"></i><b>2.2.4</b> Task API</a><ul>
<li class="chapter" data-level="2.2.4.1" data-path="tasks.html"><a href="tasks.html#tasks-retrieving"><i class="fa fa-check"></i><b>2.2.4.1</b> Retrieving Data</a></li>
<li class="chapter" data-level="2.2.4.2" data-path="tasks.html"><a href="tasks.html#tasks-roles"><i class="fa fa-check"></i><b>2.2.4.2</b> Roles (Rows and Columns)</a></li>
<li class="chapter" data-level="2.2.4.3" data-path="tasks.html"><a href="tasks.html#tasks-mutators"><i class="fa fa-check"></i><b>2.2.4.3</b> Task Mutators</a></li>
</ul></li>
<li class="chapter" data-level="2.2.5" data-path="tasks.html"><a href="tasks.html#autoplot-task"><i class="fa fa-check"></i><b>2.2.5</b> Plotting Tasks</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="learners.html"><a href="learners.html"><i class="fa fa-check"></i><b>2.3</b> Learners</a><ul>
<li class="chapter" data-level="2.3.1" data-path="learners.html"><a href="learners.html#learners-predefined"><i class="fa fa-check"></i><b>2.3.1</b> Predefined Learners</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="train-predict.html"><a href="train-predict.html"><i class="fa fa-check"></i><b>2.4</b> Train and Predict</a><ul>
<li class="chapter" data-level="2.4.1" data-path="train-predict.html"><a href="train-predict.html#train-predict-objects"><i class="fa fa-check"></i><b>2.4.1</b> Creating Task and Learner Objects</a></li>
<li class="chapter" data-level="2.4.2" data-path="train-predict.html"><a href="train-predict.html#split-data"><i class="fa fa-check"></i><b>2.4.2</b> Setting up the train/test splits of the data</a></li>
<li class="chapter" data-level="2.4.3" data-path="train-predict.html"><a href="train-predict.html#training"><i class="fa fa-check"></i><b>2.4.3</b> Training the learner</a></li>
<li class="chapter" data-level="2.4.4" data-path="train-predict.html"><a href="train-predict.html#predicting"><i class="fa fa-check"></i><b>2.4.4</b> Predicting</a></li>
<li class="chapter" data-level="2.4.5" data-path="train-predict.html"><a href="train-predict.html#predict-type"><i class="fa fa-check"></i><b>2.4.5</b> Changing the Predict Type</a></li>
<li class="chapter" data-level="2.4.6" data-path="train-predict.html"><a href="train-predict.html#autoplot-prediction"><i class="fa fa-check"></i><b>2.4.6</b> Plotting Predictions</a></li>
<li class="chapter" data-level="2.4.7" data-path="train-predict.html"><a href="train-predict.html#measure"><i class="fa fa-check"></i><b>2.4.7</b> Performance assessment</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="resampling.html"><a href="resampling.html"><i class="fa fa-check"></i><b>2.5</b> Resampling</a><ul>
<li class="chapter" data-level="2.5.1" data-path="resampling.html"><a href="resampling.html#resampling-settings"><i class="fa fa-check"></i><b>2.5.1</b> Settings</a></li>
<li class="chapter" data-level="2.5.2" data-path="resampling.html"><a href="resampling.html#resampling-inst"><i class="fa fa-check"></i><b>2.5.2</b> Instantiation</a></li>
<li class="chapter" data-level="2.5.3" data-path="resampling.html"><a href="resampling.html#resampling-exec"><i class="fa fa-check"></i><b>2.5.3</b> Execution</a></li>
<li class="chapter" data-level="2.5.4" data-path="resampling.html"><a href="resampling.html#resamp-custom"><i class="fa fa-check"></i><b>2.5.4</b> Custom resampling</a></li>
<li class="chapter" data-level="2.5.5" data-path="resampling.html"><a href="resampling.html#autoplot-resampleresult"><i class="fa fa-check"></i><b>2.5.5</b> Plotting Resample Results</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="benchmarking.html"><a href="benchmarking.html"><i class="fa fa-check"></i><b>2.6</b> Benchmarking</a><ul>
<li class="chapter" data-level="2.6.1" data-path="benchmarking.html"><a href="benchmarking.html#bm-design"><i class="fa fa-check"></i><b>2.6.1</b> Design Creation</a></li>
<li class="chapter" data-level="2.6.2" data-path="benchmarking.html"><a href="benchmarking.html#bm-exec"><i class="fa fa-check"></i><b>2.6.2</b> Execution and Aggregation of Results</a></li>
<li class="chapter" data-level="2.6.3" data-path="benchmarking.html"><a href="benchmarking.html#autoplot-benchmarkresult"><i class="fa fa-check"></i><b>2.6.3</b> Plotting Benchmark Results</a></li>
<li class="chapter" data-level="2.6.4" data-path="benchmarking.html"><a href="benchmarking.html#bm-resamp"><i class="fa fa-check"></i><b>2.6.4</b> Extracting ResampleResults</a></li>
<li class="chapter" data-level="2.6.5" data-path="benchmarking.html"><a href="benchmarking.html#converting-and-merging-resampleresults"><i class="fa fa-check"></i><b>2.6.5</b> Converting and Merging ResampleResults</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="binary-classification.html"><a href="binary-classification.html"><i class="fa fa-check"></i><b>2.7</b> Binary classification</a><ul>
<li class="chapter" data-level="2.7.1" data-path="binary-classification.html"><a href="binary-classification.html#binary-roc"><i class="fa fa-check"></i><b>2.7.1</b> ROC Curve and Thresholds</a></li>
<li class="chapter" data-level="2.7.2" data-path="binary-classification.html"><a href="binary-classification.html#threshold-tuning"><i class="fa fa-check"></i><b>2.7.2</b> Threshold Tuning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="optimization.html"><a href="optimization.html"><i class="fa fa-check"></i><b>3</b> Model Optimization</a><ul>
<li class="chapter" data-level="3.1" data-path="tuning.html"><a href="tuning.html"><i class="fa fa-check"></i><b>3.1</b> Hyperparameter Tuning</a><ul>
<li class="chapter" data-level="3.1.1" data-path="tuning.html"><a href="tuning.html#tuning-optimization"><i class="fa fa-check"></i><b>3.1.1</b> The <code>TuningInstance</code> Classes</a></li>
<li class="chapter" data-level="3.1.2" data-path="tuning.html"><a href="tuning.html#the-tuner-class"><i class="fa fa-check"></i><b>3.1.2</b> The <code>Tuner</code> Class</a></li>
<li class="chapter" data-level="3.1.3" data-path="tuning.html"><a href="tuning.html#tuning-triggering"><i class="fa fa-check"></i><b>3.1.3</b> Triggering the Tuning</a></li>
<li class="chapter" data-level="3.1.4" data-path="tuning.html"><a href="tuning.html#autotuner"><i class="fa fa-check"></i><b>3.1.4</b> Automating the Tuning</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="fs.html"><a href="fs.html"><i class="fa fa-check"></i><b>3.2</b> Feature Selection / Filtering</a><ul>
<li class="chapter" data-level="3.2.1" data-path="fs.html"><a href="fs.html#fs-filter"><i class="fa fa-check"></i><b>3.2.1</b> Filters</a></li>
<li class="chapter" data-level="3.2.2" data-path="fs.html"><a href="fs.html#fs-calc"><i class="fa fa-check"></i><b>3.2.2</b> Calculating filter values</a></li>
<li class="chapter" data-level="3.2.3" data-path="fs.html"><a href="fs.html#fs-var-imp-filters"><i class="fa fa-check"></i><b>3.2.3</b> Variable Importance Filters</a></li>
<li class="chapter" data-level="3.2.4" data-path="fs.html"><a href="fs.html#fs-ensemble"><i class="fa fa-check"></i><b>3.2.4</b> Ensemble Methods</a></li>
<li class="chapter" data-level="3.2.5" data-path="fs.html"><a href="fs.html#fs-wrapper"><i class="fa fa-check"></i><b>3.2.5</b> Wrapper Methods</a></li>
<li class="chapter" data-level="3.2.6" data-path="fs.html"><a href="fs.html#fs-wrapper-optimization"><i class="fa fa-check"></i><b>3.2.6</b> The <code>FSelectInstance</code> Classes</a></li>
<li class="chapter" data-level="3.2.7" data-path="fs.html"><a href="fs.html#the-fselector-class"><i class="fa fa-check"></i><b>3.2.7</b> The <code>FSelector</code> Class</a></li>
<li class="chapter" data-level="3.2.8" data-path="fs.html"><a href="fs.html#wrapper-selection-triggering"><i class="fa fa-check"></i><b>3.2.8</b> Triggering the Tuning</a></li>
<li class="chapter" data-level="3.2.9" data-path="fs.html"><a href="fs.html#autofselect"><i class="fa fa-check"></i><b>3.2.9</b> Automating the Feature Selection</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="nested-resampling.html"><a href="nested-resampling.html"><i class="fa fa-check"></i><b>3.3</b> Nested Resampling</a><ul>
<li class="chapter" data-level="3.3.1" data-path="nested-resampling.html"><a href="nested-resampling.html#nested-resamp-exec"><i class="fa fa-check"></i><b>3.3.1</b> Execution</a></li>
<li class="chapter" data-level="3.3.2" data-path="nested-resampling.html"><a href="nested-resampling.html#nested-resamp-eval"><i class="fa fa-check"></i><b>3.3.2</b> Evaluation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="pipelines.html"><a href="pipelines.html"><i class="fa fa-check"></i><b>4</b> Pipelines</a><ul>
<li class="chapter" data-level="4.1" data-path="pipe-pipeops.html"><a href="pipe-pipeops.html"><i class="fa fa-check"></i><b>4.1</b> The Building Blocks: PipeOps</a></li>
<li class="chapter" data-level="4.2" data-path="pipe-operator.html"><a href="pipe-operator.html"><i class="fa fa-check"></i><b>4.2</b> The Pipeline Operator: <code>%&gt;&gt;%</code></a></li>
<li class="chapter" data-level="4.3" data-path="pipe-nodes-edges-graphs.html"><a href="pipe-nodes-edges-graphs.html"><i class="fa fa-check"></i><b>4.3</b> Nodes, Edges and Graphs</a></li>
<li class="chapter" data-level="4.4" data-path="pipe-modeling.html"><a href="pipe-modeling.html"><i class="fa fa-check"></i><b>4.4</b> Modeling</a><ul>
<li class="chapter" data-level="4.4.1" data-path="pipe-modeling.html"><a href="pipe-modeling.html#pipe-hyperpars"><i class="fa fa-check"></i><b>4.4.1</b> Setting Hyperparameters</a></li>
<li class="chapter" data-level="4.4.2" data-path="pipe-modeling.html"><a href="pipe-modeling.html#pipe-tuning"><i class="fa fa-check"></i><b>4.4.2</b> Tuning</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="pipe-nonlinear.html"><a href="pipe-nonlinear.html"><i class="fa fa-check"></i><b>4.5</b> Non-Linear Graphs</a><ul>
<li class="chapter" data-level="4.5.1" data-path="pipe-nonlinear.html"><a href="pipe-nonlinear.html#pipe-model-ensembles-branching-copying"><i class="fa fa-check"></i><b>4.5.1</b> Branching &amp; Copying</a></li>
<li class="chapter" data-level="4.5.2" data-path="pipe-nonlinear.html"><a href="pipe-nonlinear.html#pipe-model-ensembles"><i class="fa fa-check"></i><b>4.5.2</b> Model Ensembles</a><ul>
<li class="chapter" data-level="4.5.2.1" data-path="pipe-nonlinear.html"><a href="pipe-nonlinear.html#pipe-model-ensembles-bagging"><i class="fa fa-check"></i><b>4.5.2.1</b> Bagging</a></li>
<li class="chapter" data-level="4.5.2.2" data-path="pipe-nonlinear.html"><a href="pipe-nonlinear.html#pipe-model-ensembles-stacking"><i class="fa fa-check"></i><b>4.5.2.2</b> Stacking</a></li>
<li class="chapter" data-level="4.5.2.3" data-path="pipe-nonlinear.html"><a href="pipe-nonlinear.html#multilevel-stacking"><i class="fa fa-check"></i><b>4.5.2.3</b> Multilevel Stacking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="pipe-special-ops.html"><a href="pipe-special-ops.html"><i class="fa fa-check"></i><b>4.6</b> Special Operators</a><ul>
<li class="chapter" data-level="4.6.1" data-path="pipe-special-ops.html"><a href="pipe-special-ops.html#imputation-pipeopimpute"><i class="fa fa-check"></i><b>4.6.1</b> Imputation: <code>PipeOpImpute</code></a></li>
<li class="chapter" data-level="4.6.2" data-path="pipe-special-ops.html"><a href="pipe-special-ops.html#feature-engineering-pipeopmutate"><i class="fa fa-check"></i><b>4.6.2</b> Feature Engineering: <code>PipeOpMutate</code></a></li>
<li class="chapter" data-level="4.6.3" data-path="pipe-special-ops.html"><a href="pipe-special-ops.html#training-on-data-subsets-pipeopchunk"><i class="fa fa-check"></i><b>4.6.3</b> Training on data subsets: <code>PipeOpChunk</code></a></li>
<li class="chapter" data-level="4.6.4" data-path="pipe-special-ops.html"><a href="pipe-special-ops.html#feature-selection-pipeopfilter-and-pipeopselect"><i class="fa fa-check"></i><b>4.6.4</b> Feature Selection: <code>PipeOpFilter</code> and <code>PipeOpSelect</code></a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html"><i class="fa fa-check"></i><b>4.7</b> In-depth look into mlr3pipelines</a><ul>
<li class="chapter" data-level="4.7.1" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#whats-the-point"><i class="fa fa-check"></i><b>4.7.1</b> What’s the Point</a></li>
<li class="chapter" data-level="4.7.2" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#pipeop-pipeline-operators"><i class="fa fa-check"></i><b>4.7.2</b> <code>PipeOp</code>: Pipeline Operators</a><ul>
<li class="chapter" data-level="4.7.2.1" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#why-the-state"><i class="fa fa-check"></i><b>4.7.2.1</b> Why the <code>$state</code></a></li>
<li class="chapter" data-level="4.7.2.2" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#where-to-get-pipeops"><i class="fa fa-check"></i><b>4.7.2.2</b> Where to Get <code>PipeOp</code>s</a></li>
</ul></li>
<li class="chapter" data-level="4.7.3" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#pipeop-channels"><i class="fa fa-check"></i><b>4.7.3</b> PipeOp Channels</a><ul>
<li class="chapter" data-level="4.7.3.1" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#input-channels"><i class="fa fa-check"></i><b>4.7.3.1</b> Input Channels</a></li>
<li class="chapter" data-level="4.7.3.2" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#output-channels"><i class="fa fa-check"></i><b>4.7.3.2</b> Output Channels</a></li>
<li class="chapter" data-level="4.7.3.3" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#channel-configuration"><i class="fa fa-check"></i><b>4.7.3.3</b> Channel Configuration</a></li>
</ul></li>
<li class="chapter" data-level="4.7.4" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#graph-networks-of-pipeops"><i class="fa fa-check"></i><b>4.7.4</b> <code>Graph</code>: Networks of <code>PipeOp</code>s</a><ul>
<li class="chapter" data-level="4.7.4.1" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#basics-1"><i class="fa fa-check"></i><b>4.7.4.1</b> Basics</a></li>
<li class="chapter" data-level="4.7.4.2" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#networks"><i class="fa fa-check"></i><b>4.7.4.2</b> Networks</a></li>
<li class="chapter" data-level="4.7.4.3" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#syntactic-sugar"><i class="fa fa-check"></i><b>4.7.4.3</b> Syntactic Sugar</a></li>
<li class="chapter" data-level="4.7.4.4" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#pipeop-ids-and-id-name-clashes"><i class="fa fa-check"></i><b>4.7.4.4</b> <code>PipeOp</code> IDs and ID Name Clashes</a></li>
</ul></li>
<li class="chapter" data-level="4.7.5" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#learners-in-graphs-graphs-in-learners"><i class="fa fa-check"></i><b>4.7.5</b> Learners in Graphs, Graphs in Learners</a><ul>
<li class="chapter" data-level="4.7.5.1" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#pipeoplearner"><i class="fa fa-check"></i><b>4.7.5.1</b> <code>PipeOpLearner</code></a></li>
<li class="chapter" data-level="4.7.5.2" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#graphlearner"><i class="fa fa-check"></i><b>4.7.5.2</b> <code>GraphLearner</code></a></li>
</ul></li>
<li class="chapter" data-level="4.7.6" data-path="in-depth-pipelines.html"><a href="in-depth-pipelines.html#hyperparameters"><i class="fa fa-check"></i><b>4.7.6</b> Hyperparameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="technical.html"><a href="technical.html"><i class="fa fa-check"></i><b>5</b> Technical</a><ul>
<li class="chapter" data-level="5.1" data-path="parallelization.html"><a href="parallelization.html"><i class="fa fa-check"></i><b>5.1</b> Parallelization</a><ul>
<li class="chapter" data-level="5.1.1" data-path="parallelization.html"><a href="parallelization.html#nested-resampling-parallelization"><i class="fa fa-check"></i><b>5.1.1</b> Nested Resampling Parallelization</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="error-handling.html"><a href="error-handling.html"><i class="fa fa-check"></i><b>5.2</b> Error Handling</a><ul>
<li class="chapter" data-level="5.2.1" data-path="error-handling.html"><a href="error-handling.html#encapsulation"><i class="fa fa-check"></i><b>5.2.1</b> Encapsulation</a></li>
<li class="chapter" data-level="5.2.2" data-path="error-handling.html"><a href="error-handling.html#fallback-learners"><i class="fa fa-check"></i><b>5.2.2</b> Fallback learners</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="backends.html"><a href="backends.html"><i class="fa fa-check"></i><b>5.3</b> Database Backends</a><ul>
<li class="chapter" data-level="5.3.1" data-path="backends.html"><a href="backends.html#use-case-nyc-flights"><i class="fa fa-check"></i><b>5.3.1</b> Use Case: NYC Flights</a></li>
<li class="chapter" data-level="5.3.2" data-path="backends.html"><a href="backends.html#preprocessing-with-dplyr"><i class="fa fa-check"></i><b>5.3.2</b> Preprocessing with <code>dplyr</code></a></li>
<li class="chapter" data-level="5.3.3" data-path="backends.html"><a href="backends.html#databackenddplyr"><i class="fa fa-check"></i><b>5.3.3</b> DataBackendDplyr</a></li>
<li class="chapter" data-level="5.3.4" data-path="backends.html"><a href="backends.html#model-fitting"><i class="fa fa-check"></i><b>5.3.4</b> Model fitting</a></li>
<li class="chapter" data-level="5.3.5" data-path="backends.html"><a href="backends.html#cleanup"><i class="fa fa-check"></i><b>5.3.5</b> Cleanup</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="paradox.html"><a href="paradox.html"><i class="fa fa-check"></i><b>5.4</b> Parameters (using <code>paradox</code>)</a><ul>
<li class="chapter" data-level="5.4.1" data-path="paradox.html"><a href="paradox.html#reference-based-objects"><i class="fa fa-check"></i><b>5.4.1</b> Reference Based Objects</a></li>
<li class="chapter" data-level="5.4.2" data-path="paradox.html"><a href="paradox.html#defining-a-parameter-space"><i class="fa fa-check"></i><b>5.4.2</b> Defining a Parameter Space</a><ul>
<li class="chapter" data-level="5.4.2.1" data-path="paradox.html"><a href="paradox.html#single-parameters"><i class="fa fa-check"></i><b>5.4.2.1</b> Single Parameters</a></li>
<li class="chapter" data-level="5.4.2.2" data-path="paradox.html"><a href="paradox.html#parameter-sets"><i class="fa fa-check"></i><b>5.4.2.2</b> Parameter Sets</a></li>
<li class="chapter" data-level="5.4.2.3" data-path="paradox.html"><a href="paradox.html#vector-parameters"><i class="fa fa-check"></i><b>5.4.2.3</b> Vector Parameters</a></li>
</ul></li>
<li class="chapter" data-level="5.4.3" data-path="paradox.html"><a href="paradox.html#parameter-sampling"><i class="fa fa-check"></i><b>5.4.3</b> Parameter Sampling</a><ul>
<li class="chapter" data-level="5.4.3.1" data-path="paradox.html"><a href="paradox.html#parameter-designs"><i class="fa fa-check"></i><b>5.4.3.1</b> Parameter Designs</a></li>
<li class="chapter" data-level="5.4.3.2" data-path="paradox.html"><a href="paradox.html#grid-design"><i class="fa fa-check"></i><b>5.4.3.2</b> Grid Design</a></li>
<li class="chapter" data-level="5.4.3.3" data-path="paradox.html"><a href="paradox.html#random-sampling"><i class="fa fa-check"></i><b>5.4.3.3</b> Random Sampling</a></li>
<li class="chapter" data-level="5.4.3.4" data-path="paradox.html"><a href="paradox.html#generalized-sampling-the-sampler-class"><i class="fa fa-check"></i><b>5.4.3.4</b> Generalized Sampling: The <code>Sampler</code> Class</a></li>
</ul></li>
<li class="chapter" data-level="5.4.4" data-path="paradox.html"><a href="paradox.html#parameter-transformation"><i class="fa fa-check"></i><b>5.4.4</b> Parameter Transformation</a><ul>
<li class="chapter" data-level="5.4.4.1" data-path="paradox.html"><a href="paradox.html#transformation-between-types"><i class="fa fa-check"></i><b>5.4.4.1</b> Transformation between Types</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="logging.html"><a href="logging.html"><i class="fa fa-check"></i><b>5.5</b> Logging</a><ul>
<li class="chapter" data-level="5.5.1" data-path="logging.html"><a href="logging.html#changing-mlr3-logging-levels"><i class="fa fa-check"></i><b>5.5.1</b> Changing mlr3 logging levels</a></li>
<li class="chapter" data-level="5.5.2" data-path="logging.html"><a href="logging.html#redirecting-output"><i class="fa fa-check"></i><b>5.5.2</b> Redirecting output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="extending.html"><a href="extending.html"><i class="fa fa-check"></i><b>6</b> Extending</a><ul>
<li class="chapter" data-level="6.1" data-path="extending-learners.html"><a href="extending-learners.html"><i class="fa fa-check"></i><b>6.1</b> Adding new Learners</a><ul>
<li class="chapter" data-level="6.1.1" data-path="extending-learners.html"><a href="extending-learners.html#create-learner"><i class="fa fa-check"></i><b>6.1.1</b> Calling create_learner</a></li>
<li class="chapter" data-level="6.1.2" data-path="extending-learners.html"><a href="extending-learners.html#learner_package_type_key.r"><i class="fa fa-check"></i><b>6.1.2</b> learner_package_type_key.R</a></li>
<li class="chapter" data-level="6.1.3" data-path="extending-learners.html"><a href="extending-learners.html#learner-meta-information"><i class="fa fa-check"></i><b>6.1.3</b> Meta-information</a></li>
<li class="chapter" data-level="6.1.4" data-path="extending-learners.html"><a href="extending-learners.html#param-set"><i class="fa fa-check"></i><b>6.1.4</b> ParamSet</a></li>
<li class="chapter" data-level="6.1.5" data-path="extending-learners.html"><a href="extending-learners.html#learner-train"><i class="fa fa-check"></i><b>6.1.5</b> Train function</a></li>
<li class="chapter" data-level="6.1.6" data-path="extending-learners.html"><a href="extending-learners.html#learner-predict"><i class="fa fa-check"></i><b>6.1.6</b> Predict function</a></li>
<li class="chapter" data-level="6.1.7" data-path="extending-learners.html"><a href="extending-learners.html#learner-control"><i class="fa fa-check"></i><b>6.1.7</b> Control objects/functions of learners</a></li>
<li class="chapter" data-level="6.1.8" data-path="extending-learners.html"><a href="extending-learners.html#learner-test"><i class="fa fa-check"></i><b>6.1.8</b> Testing the learner</a><ul>
<li class="chapter" data-level="6.1.8.1" data-path="extending-learners.html"><a href="extending-learners.html#learner-test-manual"><i class="fa fa-check"></i><b>6.1.8.1</b> Train and Predict</a></li>
<li class="chapter" data-level="6.1.8.2" data-path="extending-learners.html"><a href="extending-learners.html#learner-test-unit"><i class="fa fa-check"></i><b>6.1.8.2</b> Autotest</a></li>
<li class="chapter" data-level="6.1.8.3" data-path="extending-learners.html"><a href="extending-learners.html#learner-test-parameter"><i class="fa fa-check"></i><b>6.1.8.3</b> Checking Parameters</a></li>
</ul></li>
<li class="chapter" data-level="6.1.9" data-path="extending-learners.html"><a href="extending-learners.html#cleaning"><i class="fa fa-check"></i><b>6.1.9</b> Package Cleaning</a></li>
<li class="chapter" data-level="6.1.10" data-path="extending-learners.html"><a href="extending-learners.html#thanks-and-maintenance"><i class="fa fa-check"></i><b>6.1.10</b> Thanks and Maintenance</a></li>
<li class="chapter" data-level="6.1.11" data-path="extending-learners.html"><a href="extending-learners.html#learner-faq"><i class="fa fa-check"></i><b>6.1.11</b> Learner FAQ</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="extending-measures.html"><a href="extending-measures.html"><i class="fa fa-check"></i><b>6.2</b> Adding new Measures</a></li>
<li class="chapter" data-level="6.3" data-path="extending-pipeops.html"><a href="extending-pipeops.html"><i class="fa fa-check"></i><b>6.3</b> Adding new PipeOps</a><ul>
<li class="chapter" data-level="6.3.1" data-path="extending-pipeops.html"><a href="extending-pipeops.html#ext-pipeopcopy"><i class="fa fa-check"></i><b>6.3.1</b> General Case Example: <code>PipeOpCopy</code></a><ul>
<li class="chapter" data-level="6.3.1.1" data-path="extending-pipeops.html"><a href="extending-pipeops.html#first-steps-inheriting-from-pipeop"><i class="fa fa-check"></i><b>6.3.1.1</b> First Steps: Inheriting from <code>PipeOp</code></a></li>
<li class="chapter" data-level="6.3.1.2" data-path="extending-pipeops.html"><a href="extending-pipeops.html#channel-definitions"><i class="fa fa-check"></i><b>6.3.1.2</b> Channel Definitions</a></li>
<li class="chapter" data-level="6.3.1.3" data-path="extending-pipeops.html"><a href="extending-pipeops.html#train-and-predict"><i class="fa fa-check"></i><b>6.3.1.3</b> Train and Predict</a></li>
<li class="chapter" data-level="6.3.1.4" data-path="extending-pipeops.html"><a href="extending-pipeops.html#putting-it-together"><i class="fa fa-check"></i><b>6.3.1.4</b> Putting it Together</a></li>
</ul></li>
<li class="chapter" data-level="6.3.2" data-path="extending-pipeops.html"><a href="extending-pipeops.html#ext-pipe-preproc"><i class="fa fa-check"></i><b>6.3.2</b> Special Case: Preprocessing</a><ul>
<li class="chapter" data-level="6.3.2.1" data-path="extending-pipeops.html"><a href="extending-pipeops.html#example-pipeopdropna"><i class="fa fa-check"></i><b>6.3.2.1</b> Example: <code>PipeOpDropNA</code></a></li>
<li class="chapter" data-level="6.3.2.2" data-path="extending-pipeops.html"><a href="extending-pipeops.html#example-pipeopscalealways"><i class="fa fa-check"></i><b>6.3.2.2</b> Example: <code>PipeOpScaleAlways</code></a></li>
</ul></li>
<li class="chapter" data-level="6.3.3" data-path="extending-pipeops.html"><a href="extending-pipeops.html#special-case-preprocessing-with-simple-train"><i class="fa fa-check"></i><b>6.3.3</b> Special Case: Preprocessing with Simple Train</a><ul>
<li class="chapter" data-level="6.3.3.1" data-path="extending-pipeops.html"><a href="extending-pipeops.html#example-pipeopdropconst"><i class="fa fa-check"></i><b>6.3.3.1</b> Example: <code>PipeOpDropConst</code></a></li>
<li class="chapter" data-level="6.3.3.2" data-path="extending-pipeops.html"><a href="extending-pipeops.html#example-pipeopscalealwayssimple"><i class="fa fa-check"></i><b>6.3.3.2</b> Example: <code>PipeOpScaleAlwaysSimple</code></a></li>
</ul></li>
<li class="chapter" data-level="6.3.4" data-path="extending-pipeops.html"><a href="extending-pipeops.html#ext-pipe-hyperpars"><i class="fa fa-check"></i><b>6.3.4</b> Hyperparameters</a><ul>
<li class="chapter" data-level="6.3.4.1" data-path="extending-pipeops.html"><a href="extending-pipeops.html#hyperparameter-example-pipeopscale"><i class="fa fa-check"></i><b>6.3.4.1</b> Hyperparameter Example: <code>PipeOpScale</code></a></li>
</ul></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="special-tasks.html"><a href="special-tasks.html"><i class="fa fa-check"></i><b>7</b> Special Tasks</a><ul>
<li class="chapter" data-level="7.1" data-path="survival.html"><a href="survival.html"><i class="fa fa-check"></i><b>7.1</b> Survival Analysis</a><ul>
<li class="chapter" data-level="7.1.1" data-path="survival.html"><a href="survival.html#tasksurv"><i class="fa fa-check"></i><b>7.1.1</b> TaskSurv</a></li>
<li class="chapter" data-level="7.1.2" data-path="survival.html"><a href="survival.html#predict-types---crank-lp-and-distr"><i class="fa fa-check"></i><b>7.1.2</b> Predict Types - crank, lp, and distr</a></li>
<li class="chapter" data-level="7.1.3" data-path="survival.html"><a href="survival.html#composition"><i class="fa fa-check"></i><b>7.1.3</b> Composition</a></li>
<li class="chapter" data-level="7.1.4" data-path="survival.html"><a href="survival.html#benchmark-experiment"><i class="fa fa-check"></i><b>7.1.4</b> Benchmark Experiment</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="spatiotemporal.html"><a href="spatiotemporal.html"><i class="fa fa-check"></i><b>7.2</b> Spatiotemporal Analysis</a><ul>
<li class="chapter" data-level="7.2.1" data-path="spatiotemporal.html"><a href="spatiotemporal.html#spatiotemporal-intro"><i class="fa fa-check"></i><b>7.2.1</b> Autocorrelation</a></li>
<li class="chapter" data-level="7.2.2" data-path="spatiotemporal.html"><a href="spatiotemporal.html#sp-vs-nsp-cv"><i class="fa fa-check"></i><b>7.2.2</b> Spatial CV vs. Non-Spatial CV</a><ul>
<li class="chapter" data-level="7.2.2.1" data-path="spatiotemporal.html"><a href="spatiotemporal.html#nsp-cv"><i class="fa fa-check"></i><b>7.2.2.1</b> Non-Spatial CV</a></li>
<li class="chapter" data-level="7.2.2.2" data-path="spatiotemporal.html"><a href="spatiotemporal.html#sp-cv"><i class="fa fa-check"></i><b>7.2.2.2</b> Spatial CV</a></li>
<li class="chapter" data-level="7.2.2.3" data-path="spatiotemporal.html"><a href="spatiotemporal.html#vis-spt-partitions"><i class="fa fa-check"></i><b>7.2.2.3</b> Visualization of Spatiotemporal Partitions</a></li>
</ul></li>
<li class="chapter" data-level="7.2.3" data-path="spatiotemporal.html"><a href="spatiotemporal.html#choose-spt-rsmp"><i class="fa fa-check"></i><b>7.2.3</b> Choosing a Resampling Method</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ordinal.html"><a href="ordinal.html"><i class="fa fa-check"></i><b>7.3</b> Ordinal Analysis</a></li>
<li class="chapter" data-level="7.4" data-path="functional.html"><a href="functional.html"><i class="fa fa-check"></i><b>7.4</b> Functional Analysis</a><ul>
<li class="chapter" data-level="7.4.1" data-path="functional.html"><a href="functional.html#how-to-model-functional-data"><i class="fa fa-check"></i><b>7.4.1</b> How to model functional data?</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="multilabel.html"><a href="multilabel.html"><i class="fa fa-check"></i><b>7.5</b> Multilabel Classification</a></li>
<li class="chapter" data-level="7.6" data-path="cost-sens.html"><a href="cost-sens.html"><i class="fa fa-check"></i><b>7.6</b> Cost-Sensitive Classification</a><ul>
<li class="chapter" data-level="7.6.1" data-path="cost-sens.html"><a href="cost-sens.html#a-first-model"><i class="fa fa-check"></i><b>7.6.1</b> A First Model</a></li>
<li class="chapter" data-level="7.6.2" data-path="cost-sens.html"><a href="cost-sens.html#cost-sensitive-measure"><i class="fa fa-check"></i><b>7.6.2</b> Cost-sensitive Measure</a></li>
<li class="chapter" data-level="7.6.3" data-path="cost-sens.html"><a href="cost-sens.html#thresholding"><i class="fa fa-check"></i><b>7.6.3</b> Thresholding</a></li>
<li class="chapter" data-level="7.6.4" data-path="cost-sens.html"><a href="cost-sens.html#threshold-tuning-1"><i class="fa fa-check"></i><b>7.6.4</b> Threshold Tuning</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>7.7</b> Prerequisites</a></li>
<li class="chapter" data-level="7.8" data-path="adjusting-thresholds-two-strategies.html"><a href="adjusting-thresholds-two-strategies.html"><i class="fa fa-check"></i><b>7.8</b> Adjusting thresholds: Two strategies</a></li>
<li class="chapter" data-level="7.9" data-path="pipeopthreshold.html"><a href="pipeopthreshold.html"><i class="fa fa-check"></i><b>7.9</b> PipeOpThreshold</a></li>
<li class="chapter" data-level="7.10" data-path="pipeoptunethreshold.html"><a href="pipeoptunethreshold.html"><i class="fa fa-check"></i><b>7.10</b> PipeOpTunethreshold</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="interpretation.html"><a href="interpretation.html"><i class="fa fa-check"></i><b>8</b> Model Interpretation</a><ul>
<li class="chapter" data-level="8.1" data-path="iml.html"><a href="iml.html"><i class="fa fa-check"></i><b>8.1</b> IML</a><ul>
<li class="chapter" data-level="8.1.1" data-path="iml.html"><a href="iml.html#iml-intro"><i class="fa fa-check"></i><b>8.1.1</b> Introduction</a></li>
<li class="chapter" data-level="8.1.2" data-path="iml.html"><a href="iml.html#setup"><i class="fa fa-check"></i><b>8.1.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="interpretability-dalex.html"><a href="interpretability-dalex.html"><i class="fa fa-check"></i><b>8.2</b> DALEX</a><ul>
<li class="chapter" data-level="8.2.1" data-path="interpretability-dalex.html"><a href="interpretability-dalex.html#interpretability-dalex-introduction"><i class="fa fa-check"></i><b>8.2.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2.2" data-path="interpretability-dalex.html"><a href="interpretability-dalex.html#interpretability-data-fifa"><i class="fa fa-check"></i><b>8.2.2</b> Read data: FIFA</a></li>
<li class="chapter" data-level="8.2.3" data-path="interpretability-dalex.html"><a href="interpretability-dalex.html#interpretability-train-ranger"><i class="fa fa-check"></i><b>8.2.3</b> Train a model: Ranger</a></li>
<li class="chapter" data-level="8.2.4" data-path="interpretability-dalex.html"><a href="interpretability-dalex.html#interpretability-architecture"><i class="fa fa-check"></i><b>8.2.4</b> The general workflow</a></li>
<li class="chapter" data-level="8.2.5" data-path="interpretability-dalex.html"><a href="interpretability-dalex.html#interpretability-dataset-level"><i class="fa fa-check"></i><b>8.2.5</b> Dataset level exploration</a></li>
<li class="chapter" data-level="8.2.6" data-path="interpretability-dalex.html"><a href="interpretability-dalex.html#interpretability-instance-level"><i class="fa fa-check"></i><b>8.2.6</b> Instance level explanation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>9</b> Appendix</a><ul>
<li class="chapter" data-level="9.1" data-path="list-learners.html"><a href="list-learners.html"><i class="fa fa-check"></i><b>9.1</b> Integrated Learners</a></li>
<li class="chapter" data-level="9.2" data-path="list-measures.html"><a href="list-measures.html"><i class="fa fa-check"></i><b>9.2</b> Integrated Performance Measures</a></li>
<li class="chapter" data-level="9.3" data-path="list-filters.html"><a href="list-filters.html"><i class="fa fa-check"></i><b>9.3</b> Integrated Filter Methods</a><ul>
<li class="chapter" data-level="9.3.1" data-path="list-filters.html"><a href="list-filters.html#fs-filter-list"><i class="fa fa-check"></i><b>9.3.1</b> Standalone filter methods</a></li>
<li class="chapter" data-level="9.3.2" data-path="list-filters.html"><a href="list-filters.html#fs-filter-embedded-list"><i class="fa fa-check"></i><b>9.3.2</b> Learners With Embedded Filter Methods</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="list-pipeops.html"><a href="list-pipeops.html"><i class="fa fa-check"></i><b>9.4</b> Integrated Pipe Operators</a></li>
<li class="chapter" data-level="9.5" data-path="compare-frameworks.html"><a href="compare-frameworks.html"><i class="fa fa-check"></i><b>9.5</b> Framework Comparison</a><ul>
<li class="chapter" data-level="9.5.1" data-path="compare-frameworks.html"><a href="compare-frameworks.html#an-introduction-to-pipeops"><i class="fa fa-check"></i><b>9.5.1</b> An introduction to “PipeOp”s</a><ul>
<li class="chapter" data-level="9.5.1.1" data-path="compare-frameworks.html"><a href="compare-frameworks.html#a-quick-glance-into-a-pipeop"><i class="fa fa-check"></i><b>9.5.1.1</b> A quick glance into a PipeOp</a></li>
<li class="chapter" data-level="9.5.1.2" data-path="compare-frameworks.html"><a href="compare-frameworks.html#constructing-the-pipeline"><i class="fa fa-check"></i><b>9.5.1.2</b> Constructing the Pipeline</a></li>
</ul></li>
<li class="chapter" data-level="9.5.2" data-path="compare-frameworks.html"><a href="compare-frameworks.html#mlr3pipelines-vs.-mlr"><i class="fa fa-check"></i><b>9.5.2</b> mlr3pipelines vs. mlr</a><ul>
<li class="chapter" data-level="9.5.2.1" data-path="compare-frameworks.html"><a href="compare-frameworks.html#mlr"><i class="fa fa-check"></i><b>9.5.2.1</b> mlr</a></li>
<li class="chapter" data-level="9.5.2.2" data-path="compare-frameworks.html"><a href="compare-frameworks.html#mlr3pipelines"><i class="fa fa-check"></i><b>9.5.2.2</b> mlr3pipelines</a></li>
</ul></li>
<li class="chapter" data-level="9.5.3" data-path="compare-frameworks.html"><a href="compare-frameworks.html#mlr3pipelines-vs.-sklearn.pipeline.pipeline"><i class="fa fa-check"></i><b>9.5.3</b> mlr3pipelines vs. sklearn.pipeline.Pipeline</a><ul>
<li class="chapter" data-level="9.5.3.1" data-path="compare-frameworks.html"><a href="compare-frameworks.html#sklearn"><i class="fa fa-check"></i><b>9.5.3.1</b> sklearn</a></li>
<li class="chapter" data-level="9.5.3.2" data-path="compare-frameworks.html"><a href="compare-frameworks.html#mlr3pipelines-1"><i class="fa fa-check"></i><b>9.5.3.2</b> mlr3pipelines</a></li>
</ul></li>
<li class="chapter" data-level="9.5.4" data-path="compare-frameworks.html"><a href="compare-frameworks.html#mlr3pipelines-vs-recipes"><i class="fa fa-check"></i><b>9.5.4</b> mlr3pipelines vs recipes</a><ul>
<li class="chapter" data-level="9.5.4.1" data-path="compare-frameworks.html"><a href="compare-frameworks.html#recipes"><i class="fa fa-check"></i><b>9.5.4.1</b> recipes</a></li>
<li class="chapter" data-level="9.5.4.2" data-path="compare-frameworks.html"><a href="compare-frameworks.html#mlr3pipelines-2"><i class="fa fa-check"></i><b>9.5.4.2</b> mlr3pipelines</a></li>
</ul></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">mlr3 book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tuning" class="section level2">
<h2><span class="header-section-number">3.1</span> Hyperparameter Tuning</h2>
<p>Hyperparameters are second-order parameters of machine learning models that, while often not explicitly optimized during the model estimation process, can have an important impact on the outcome and predictive performance of a model.
Typically, hyperparameters are fixed before training a model.
However, because the output of a model can be sensitive to the specification of hyperparameters, it is often recommended to make an informed decision about which hyperparameter settings may yield better model performance.
In many cases, hyperparameter settings may be chosen <em>a priori</em>, but it can be advantageous to try different settings before fitting your model on the training data.
This process is often called model ‘tuning’.</p>
<p>Hyperparameter tuning is supported via the <a href="https://mlr3tuning.mlr-org.com">mlr3tuning</a> extension package.
Below you can find an illustration of the process:</p>
<p><img src="images/tuning_process.svg" style="display: block; margin: auto;" /></p>
<p>At the heart of <a href="https://mlr3tuning.mlr-org.com">mlr3tuning</a> are the R6 classes:</p>
<ul>
<li><a href="https://mlr3tuning.mlr-org.com/reference/TuningInstanceSingleCrit.html"><code>TuningInstanceSingleCrit</code></a>, <a href="https://mlr3tuning.mlr-org.com/reference/TuningInstanceMultiCrit.html"><code>TuningInstanceMultiCrit</code></a>: These two classes describe the tuning problem and store the results.</li>
<li><a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html"><code>Tuner</code></a>: This class is the base class for implementations of tuning algorithms.</li>
</ul>
<div id="tuning-optimization" class="section level3">
<h3><span class="header-section-number">3.1.1</span> The <code>TuningInstance</code> Classes</h3>
<p>The following sub-section examines the optimization of a simple classification tree on the <a href="https://mlr3.mlr-org.com/reference/mlr_tasks_pima.html"><code>Pima Indian Diabetes</code></a> data set.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="tuning.html#cb178-1"></a>task =<span class="st"> </span><span class="kw">tsk</span>(<span class="st">&quot;pima&quot;</span>)</span>
<span id="cb178-2"><a href="tuning.html#cb178-2"></a><span class="kw">print</span>(task)</span></code></pre></div>
<pre><code>## &lt;TaskClassif:pima&gt; (768 x 9)
## * Target: diabetes
## * Properties: twoclass
## * Features (8):
##   - dbl (8): age, glucose, insulin, mass, pedigree, pregnant, pressure,
##     triceps</code></pre>
<p>We use the classification tree from <a href="https://cran.r-project.org/package=rpart">rpart</a> and choose a subset of the hyperparameters we want to tune.
This is often referred to as the “tuning space”.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="tuning.html#cb180-1"></a>learner =<span class="st"> </span><span class="kw">lrn</span>(<span class="st">&quot;classif.rpart&quot;</span>)</span>
<span id="cb180-2"><a href="tuning.html#cb180-2"></a>learner<span class="op">$</span>param_set</span></code></pre></div>
<pre><code>## &lt;ParamSet&gt;
##                 id    class lower upper      levels        default value
##  1:       minsplit ParamInt     1   Inf                         20      
##  2:      minbucket ParamInt     1   Inf             &lt;NoDefault[3]&gt;      
##  3:             cp ParamDbl     0     1                       0.01      
##  4:     maxcompete ParamInt     0   Inf                          4      
##  5:   maxsurrogate ParamInt     0   Inf                          5      
##  6:       maxdepth ParamInt     1    30                         30      
##  7:   usesurrogate ParamInt     0     2                          2      
##  8: surrogatestyle ParamInt     0     1                          0      
##  9:           xval ParamInt     0   Inf                         10     0
## 10:     keep_model ParamLgl    NA    NA  TRUE,FALSE          FALSE</code></pre>
<p>Here, we opt to tune two parameters:</p>
<ul>
<li>The complexity <code>cp</code></li>
<li>The termination criterion <code>minsplit</code></li>
</ul>
<p>The tuning space needs to be bounded, therefore one has to set lower and upper bounds:</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="tuning.html#cb182-1"></a><span class="kw">library</span>(<span class="st">&quot;paradox&quot;</span>)</span>
<span id="cb182-2"><a href="tuning.html#cb182-2"></a>tune_ps =<span class="st"> </span>ParamSet<span class="op">$</span><span class="kw">new</span>(<span class="kw">list</span>(</span>
<span id="cb182-3"><a href="tuning.html#cb182-3"></a>  ParamDbl<span class="op">$</span><span class="kw">new</span>(<span class="st">&quot;cp&quot;</span>, <span class="dt">lower =</span> <span class="fl">0.001</span>, <span class="dt">upper =</span> <span class="fl">0.1</span>),</span>
<span id="cb182-4"><a href="tuning.html#cb182-4"></a>  ParamInt<span class="op">$</span><span class="kw">new</span>(<span class="st">&quot;minsplit&quot;</span>, <span class="dt">lower =</span> <span class="dv">1</span>, <span class="dt">upper =</span> <span class="dv">10</span>)</span>
<span id="cb182-5"><a href="tuning.html#cb182-5"></a>))</span>
<span id="cb182-6"><a href="tuning.html#cb182-6"></a>tune_ps</span></code></pre></div>
<pre><code>## &lt;ParamSet&gt;
##          id    class lower upper levels        default value
## 1:       cp ParamDbl 0.001   0.1        &lt;NoDefault[3]&gt;      
## 2: minsplit ParamInt 1.000  10.0        &lt;NoDefault[3]&gt;</code></pre>
<p>Next, we need to specify how to evaluate the performance.
For this, we need to choose a <a href="https://mlr3.mlr-org.com/reference/Resampling.html"><code>resampling strategy</code></a> and a <a href="https://mlr3.mlr-org.com/reference/Measure.html"><code>performance measure</code></a>.</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="tuning.html#cb184-1"></a>hout =<span class="st"> </span><span class="kw">rsmp</span>(<span class="st">&quot;holdout&quot;</span>)</span>
<span id="cb184-2"><a href="tuning.html#cb184-2"></a>measure =<span class="st"> </span><span class="kw">msr</span>(<span class="st">&quot;classif.ce&quot;</span>)</span></code></pre></div>
<p>Finally, one has to select the budget available, to solve this tuning instance.
This is done by selecting one of the available <a href="https://bbotk.mlr-org.com/reference/Terminator.html"><code>Terminators</code></a>:</p>
<ul>
<li>Terminate after a given time (<a href="https://bbotk.mlr-org.com/reference/mlr_terminators_clock_time.html"><code>TerminatorClockTime</code></a>)</li>
<li>Terminate after a given amount of iterations (<a href="https://bbotk.mlr-org.com/reference/mlr_terminators_evals.html"><code>TerminatorEvals</code></a>)</li>
<li>Terminate after a specific performance is reached (<a href="https://bbotk.mlr-org.com/reference/mlr_terminators_perf_reached.html"><code>TerminatorPerfReached</code></a>)</li>
<li>Terminate when tuning does not improve (<a href="https://bbotk.mlr-org.com/reference/mlr_terminators_stagnation.html"><code>TerminatorStagnation</code></a>)</li>
<li>A combination of the above in an <em>ALL</em> or <em>ANY</em> fashion (<a href="https://bbotk.mlr-org.com/reference/mlr_terminators_combo.html"><code>TerminatorCombo</code></a>)</li>
</ul>
<p>For this short introduction, we specify a budget of 20 evaluations and then put everything together into a <a href="https://mlr3tuning.mlr-org.com/reference/TuningInstanceSingleCrit.html"><code>TuningInstanceSingleCrit</code></a>:</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="tuning.html#cb185-1"></a><span class="kw">library</span>(<span class="st">&quot;mlr3tuning&quot;</span>)</span>
<span id="cb185-2"><a href="tuning.html#cb185-2"></a></span>
<span id="cb185-3"><a href="tuning.html#cb185-3"></a>evals20 =<span class="st"> </span><span class="kw">trm</span>(<span class="st">&quot;evals&quot;</span>, <span class="dt">n_evals =</span> <span class="dv">20</span>)</span>
<span id="cb185-4"><a href="tuning.html#cb185-4"></a></span>
<span id="cb185-5"><a href="tuning.html#cb185-5"></a>instance =<span class="st"> </span>TuningInstanceSingleCrit<span class="op">$</span><span class="kw">new</span>(</span>
<span id="cb185-6"><a href="tuning.html#cb185-6"></a>  <span class="dt">task =</span> task,</span>
<span id="cb185-7"><a href="tuning.html#cb185-7"></a>  <span class="dt">learner =</span> learner,</span>
<span id="cb185-8"><a href="tuning.html#cb185-8"></a>  <span class="dt">resampling =</span> hout,</span>
<span id="cb185-9"><a href="tuning.html#cb185-9"></a>  <span class="dt">measure =</span> measure,</span>
<span id="cb185-10"><a href="tuning.html#cb185-10"></a>  <span class="dt">search_space =</span> tune_ps,</span>
<span id="cb185-11"><a href="tuning.html#cb185-11"></a>  <span class="dt">terminator =</span> evals20</span>
<span id="cb185-12"><a href="tuning.html#cb185-12"></a>)</span>
<span id="cb185-13"><a href="tuning.html#cb185-13"></a>instance</span></code></pre></div>
<pre><code>## &lt;TuningInstanceSingleCrit&gt;
## * State:  Not optimized
## * Objective: &lt;ObjectiveTuning:classif.rpart_on_pima&gt;
## * Search Space:
## &lt;ParamSet&gt;
##          id    class lower upper levels        default value
## 1:       cp ParamDbl 0.001   0.1        &lt;NoDefault[3]&gt;      
## 2: minsplit ParamInt 1.000  10.0        &lt;NoDefault[3]&gt;      
## * Terminator: &lt;TerminatorEvals&gt;
## * Terminated: FALSE
## * Archive:
## &lt;ArchiveTuning&gt;
## Null data.table (0 rows and 0 cols)</code></pre>
<p>To start the tuning, we still need to select how the optimization should take place.
In other words, we need to choose the <strong>optimization algorithm</strong> via the <a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html"><code>Tuner</code></a> class.</p>
</div>
<div id="the-tuner-class" class="section level3">
<h3><span class="header-section-number">3.1.2</span> The <code>Tuner</code> Class</h3>
<p>The following algorithms are currently implemented in <a href="https://mlr3tuning.mlr-org.com">mlr3tuning</a>:</p>
<ul>
<li>Grid Search (<a href="https://mlr3tuning.mlr-org.com/reference/mlr_tuners_grid_search.html"><code>TunerGridSearch</code></a>)</li>
<li>Random Search (<a href="https://mlr3tuning.mlr-org.com/reference/mlr_tuners_random_search.html"><code>TunerRandomSearch</code></a>) <span class="citation">(Bergstra and Bengio <a href="#ref-bergstra2012" role="doc-biblioref">2012</a>)</span></li>
<li>Generalized Simulated Annealing (<a href="https://mlr3tuning.mlr-org.com/reference/mlr_tuners_gensa.html"><code>TunerGenSA</code></a>)</li>
<li>Non-Linear Optimization (<a href="https://mlr3tuning.mlr-org.com/reference/mlr_tuners_nloptr.html"><code>TunerNLoptr</code></a>)</li>
</ul>
<p>In this example, we will use a simple grid search with a grid resolution of 5.</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="tuning.html#cb187-1"></a>tuner =<span class="st"> </span><span class="kw">tnr</span>(<span class="st">&quot;grid_search&quot;</span>, <span class="dt">resolution =</span> <span class="dv">5</span>)</span></code></pre></div>
<p>Since we have only numeric parameters, <a href="https://mlr3tuning.mlr-org.com/reference/mlr_tuners_grid_search.html"><code>TunerGridSearch</code></a> will create an equidistant grid between the respective upper and lower bounds.
As we have two hyperparameters with a resolution of 5, the two-dimensional grid consists of <span class="math inline">\(5^2 = 25\)</span> configurations.
Each configuration serves as a hyperparameter setting for the previously defined <a href="https://mlr3.mlr-org.com/reference/Learner.html"><code>Learner</code></a> and triggers a 3-fold cross validation on the task.
All configurations will be examined by the tuner (in a random order), until either all configurations are evaluated or the <a href="https://bbotk.mlr-org.com/reference/Terminator.html"><code>Terminator</code></a> signals that the budget is exhausted.</p>
</div>
<div id="tuning-triggering" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Triggering the Tuning</h3>
<p>To start the tuning, we simply pass the <a href="https://mlr3tuning.mlr-org.com/reference/TuningInstanceSingleCrit.html"><code>TuningInstanceSingleCrit</code></a> to the <code>$optimize()</code> method of the initialized <a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html"><code>Tuner</code></a>.
The tuner proceeds as follows:</p>
<ol style="list-style-type: decimal">
<li>The <a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html"><code>Tuner</code></a> proposes at least one hyperparameter configuration (the <a href="https://mlr3tuning.mlr-org.com/reference/Tuner.html"><code>Tuner</code></a> may propose multiple points to improve parallelization, which can be controlled via the setting <code>batch_size</code>).</li>
<li>For each configuration, the given <a href="https://mlr3.mlr-org.com/reference/Learner.html"><code>Learner</code></a> is fitted on the <a href="https://mlr3.mlr-org.com/reference/Task.html"><code>Task</code></a> using the provided <a href="https://mlr3.mlr-org.com/reference/Resampling.html"><code>Resampling</code></a>.
All evaluations are stored in the archive of the <a href="https://mlr3tuning.mlr-org.com/reference/TuningInstanceSingleCrit.html"><code>TuningInstanceSingleCrit</code></a>.</li>
<li>The <a href="https://bbotk.mlr-org.com/reference/Terminator.html"><code>Terminator</code></a> is queried if the budget is exhausted.
If the budget is not exhausted, restart with 1) until it is.</li>
<li>Determine the configuration with the best observed performance.</li>
<li>Store the best configurations as result in the instance object.
The best hyperparameter settings (<code>$result_learner_param_vals</code>) and the corresponding measured performance (<code>$result_y</code>) can be accessed from the instance.</li>
</ol>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="tuning.html#cb188-1"></a>tuner<span class="op">$</span><span class="kw">optimize</span>(instance)</span></code></pre></div>
<pre><code>## INFO  [13:37:02.873] Starting to optimize 2 parameter(s) with &#39;&lt;OptimizerGridSearch&gt;&#39; and &#39;&lt;TerminatorEvals&gt;&#39; 
## INFO  [13:37:02.911] Evaluating 1 configuration(s) 
## INFO  [13:37:03.251] Result of batch 1: 
## INFO  [13:37:03.254]   cp minsplit classif.ce                                uhash 
## INFO  [13:37:03.254]  0.1        5       0.25 4139a8a1-99a6-4eba-94a1-30f42e51978e 
## INFO  [13:37:03.256] Evaluating 1 configuration(s) 
## INFO  [13:37:03.478] Result of batch 2: 
## INFO  [13:37:03.481]       cp minsplit classif.ce                                uhash 
## INFO  [13:37:03.481]  0.02575       10     0.2227 4a6f0d6c-f69a-46c6-b9d9-42f27f5eb18a 
## INFO  [13:37:03.484] Evaluating 1 configuration(s) 
## INFO  [13:37:03.591] Result of batch 3: 
## INFO  [13:37:03.594]       cp minsplit classif.ce                                uhash 
## INFO  [13:37:03.594]  0.07525        8       0.25 d6c36ce6-b4ce-4854-b19d-1f8f2134474b 
## INFO  [13:37:03.598] Evaluating 1 configuration(s) 
## INFO  [13:37:03.715] Result of batch 4: 
## INFO  [13:37:03.717]   cp minsplit classif.ce                                uhash 
## INFO  [13:37:03.717]  0.1        1       0.25 ca8a2cc9-3492-4f20-82b8-b9340b853b18 
## INFO  [13:37:03.720] Evaluating 1 configuration(s) 
## INFO  [13:37:03.816] Result of batch 5: 
## INFO  [13:37:03.819]       cp minsplit classif.ce                                uhash 
## INFO  [13:37:03.819]  0.02575        1     0.2227 bd7dc4dc-aa5f-40fd-b307-f2f9f7b7697f 
## INFO  [13:37:03.822] Evaluating 1 configuration(s) 
## INFO  [13:37:03.922] Result of batch 6: 
## INFO  [13:37:03.925]      cp minsplit classif.ce                                uhash 
## INFO  [13:37:03.925]  0.0505        3       0.25 8945cdae-8b74-489f-97a4-4e1ca77ea7a4 
## INFO  [13:37:03.927] Evaluating 1 configuration(s) 
## INFO  [13:37:04.025] Result of batch 7: 
## INFO  [13:37:04.027]     cp minsplit classif.ce                                uhash 
## INFO  [13:37:04.027]  0.001        1      0.293 09fc8f70-bd7e-4bdd-8319-3172ed6add27 
## INFO  [13:37:04.030] Evaluating 1 configuration(s) 
## INFO  [13:37:04.132] Result of batch 8: 
## INFO  [13:37:04.135]     cp minsplit classif.ce                                uhash 
## INFO  [13:37:04.135]  0.001        5     0.2773 3518e50f-3c90-4e4c-904b-2042b46bbd36 
## INFO  [13:37:04.137] Evaluating 1 configuration(s) 
## INFO  [13:37:04.234] Result of batch 9: 
## INFO  [13:37:04.236]      cp minsplit classif.ce                                uhash 
## INFO  [13:37:04.236]  0.0505        8       0.25 1f43561b-58c2-437d-9a8a-70d64be594a2 
## INFO  [13:37:04.239] Evaluating 1 configuration(s) 
## INFO  [13:37:04.340] Result of batch 10: 
## INFO  [13:37:04.343]   cp minsplit classif.ce                                uhash 
## INFO  [13:37:04.343]  0.1        3       0.25 da469625-63c6-49ce-ac9d-b00ea9350607 
## INFO  [13:37:04.345] Evaluating 1 configuration(s) 
## INFO  [13:37:04.445] Result of batch 11: 
## INFO  [13:37:04.448]     cp minsplit classif.ce                                uhash 
## INFO  [13:37:04.448]  0.001        8     0.2852 8c98e821-8940-4e23-911d-3fcc5db8e952 
## INFO  [13:37:04.451] Evaluating 1 configuration(s) 
## INFO  [13:37:04.557] Result of batch 12: 
## INFO  [13:37:04.560]     cp minsplit classif.ce                                uhash 
## INFO  [13:37:04.560]  0.001        3      0.293 45da92fe-8849-44de-9329-0ce006d1034c 
## INFO  [13:37:04.563] Evaluating 1 configuration(s) 
## INFO  [13:37:04.661] Result of batch 13: 
## INFO  [13:37:04.664]       cp minsplit classif.ce                                uhash 
## INFO  [13:37:04.664]  0.07525        1       0.25 8800797d-b751-4ddb-9ba5-04cb51eeb692 
## INFO  [13:37:04.667] Evaluating 1 configuration(s) 
## INFO  [13:37:04.767] Result of batch 14: 
## INFO  [13:37:04.770]       cp minsplit classif.ce                                uhash 
## INFO  [13:37:04.770]  0.07525       10       0.25 b8c1187b-913c-4374-92ec-089e0be46757 
## INFO  [13:37:04.773] Evaluating 1 configuration(s) 
## INFO  [13:37:04.871] Result of batch 15: 
## INFO  [13:37:04.873]     cp minsplit classif.ce                                uhash 
## INFO  [13:37:04.873]  0.001       10     0.2852 36799f3b-9775-4274-8c5b-97b7a4247f9a 
## INFO  [13:37:04.876] Evaluating 1 configuration(s) 
## INFO  [13:37:04.982] Result of batch 16: 
## INFO  [13:37:04.985]       cp minsplit classif.ce                                uhash 
## INFO  [13:37:04.985]  0.07525        3       0.25 e8b60b51-5e64-4509-a516-8187b924c639 
## INFO  [13:37:04.988] Evaluating 1 configuration(s) 
## INFO  [13:37:05.085] Result of batch 17: 
## INFO  [13:37:05.087]       cp minsplit classif.ce                                uhash 
## INFO  [13:37:05.087]  0.02575        5     0.2227 b44c8060-c330-4710-b5d1-6ec497739774 
## INFO  [13:37:05.090] Evaluating 1 configuration(s) 
## INFO  [13:37:05.194] Result of batch 18: 
## INFO  [13:37:05.196]      cp minsplit classif.ce                                uhash 
## INFO  [13:37:05.196]  0.0505        1       0.25 3abf0b56-3337-405e-b000-026455a5b016 
## INFO  [13:37:05.199] Evaluating 1 configuration(s) 
## INFO  [13:37:05.296] Result of batch 19: 
## INFO  [13:37:05.298]       cp minsplit classif.ce                                uhash 
## INFO  [13:37:05.298]  0.02575        8     0.2227 93120580-347a-4dd9-9e91-635f478b2cf4 
## INFO  [13:37:05.301] Evaluating 1 configuration(s) 
## INFO  [13:37:05.403] Result of batch 20: 
## INFO  [13:37:05.405]       cp minsplit classif.ce                                uhash 
## INFO  [13:37:05.405]  0.07525        5       0.25 6e241d72-2726-4ae2-95d2-5be35c9bb030 
## INFO  [13:37:05.413] Finished optimizing after 20 evaluation(s) 
## INFO  [13:37:05.415] Result: 
## INFO  [13:37:05.417]       cp minsplit learner_param_vals  x_domain classif.ce 
## INFO  [13:37:05.417]  0.02575       10          &lt;list[3]&gt; &lt;list[2]&gt;     0.2227</code></pre>
<pre><code>##         cp minsplit learner_param_vals  x_domain classif.ce
## 1: 0.02575       10          &lt;list[3]&gt; &lt;list[2]&gt;     0.2227</code></pre>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="tuning.html#cb191-1"></a>instance<span class="op">$</span>result_learner_param_vals</span></code></pre></div>
<pre><code>## $xval
## [1] 0
## 
## $cp
## [1] 0.02575
## 
## $minsplit
## [1] 10</code></pre>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="tuning.html#cb193-1"></a>instance<span class="op">$</span>result_y</span></code></pre></div>
<pre><code>## classif.ce 
##     0.2227</code></pre>
<p>One can investigate all resamplings which were undertaken, as they are stored in the archive of the <a href="https://mlr3tuning.mlr-org.com/reference/TuningInstanceSingleCrit.html"><code>TuningInstanceSingleCrit</code></a> and can be accessed through <code>$data()</code> method:</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="tuning.html#cb195-1"></a>instance<span class="op">$</span>archive<span class="op">$</span><span class="kw">data</span>()</span></code></pre></div>
<pre><code>##          cp minsplit classif.ce                                uhash  x_domain
##  1: 0.10000        5     0.2500 4139a8a1-99a6-4eba-94a1-30f42e51978e &lt;list[2]&gt;
##  2: 0.02575       10     0.2227 4a6f0d6c-f69a-46c6-b9d9-42f27f5eb18a &lt;list[2]&gt;
##  3: 0.07525        8     0.2500 d6c36ce6-b4ce-4854-b19d-1f8f2134474b &lt;list[2]&gt;
##  4: 0.10000        1     0.2500 ca8a2cc9-3492-4f20-82b8-b9340b853b18 &lt;list[2]&gt;
##  5: 0.02575        1     0.2227 bd7dc4dc-aa5f-40fd-b307-f2f9f7b7697f &lt;list[2]&gt;
##  6: 0.05050        3     0.2500 8945cdae-8b74-489f-97a4-4e1ca77ea7a4 &lt;list[2]&gt;
##  7: 0.00100        1     0.2930 09fc8f70-bd7e-4bdd-8319-3172ed6add27 &lt;list[2]&gt;
##  8: 0.00100        5     0.2773 3518e50f-3c90-4e4c-904b-2042b46bbd36 &lt;list[2]&gt;
##  9: 0.05050        8     0.2500 1f43561b-58c2-437d-9a8a-70d64be594a2 &lt;list[2]&gt;
## 10: 0.10000        3     0.2500 da469625-63c6-49ce-ac9d-b00ea9350607 &lt;list[2]&gt;
## 11: 0.00100        8     0.2852 8c98e821-8940-4e23-911d-3fcc5db8e952 &lt;list[2]&gt;
## 12: 0.00100        3     0.2930 45da92fe-8849-44de-9329-0ce006d1034c &lt;list[2]&gt;
## 13: 0.07525        1     0.2500 8800797d-b751-4ddb-9ba5-04cb51eeb692 &lt;list[2]&gt;
## 14: 0.07525       10     0.2500 b8c1187b-913c-4374-92ec-089e0be46757 &lt;list[2]&gt;
## 15: 0.00100       10     0.2852 36799f3b-9775-4274-8c5b-97b7a4247f9a &lt;list[2]&gt;
## 16: 0.07525        3     0.2500 e8b60b51-5e64-4509-a516-8187b924c639 &lt;list[2]&gt;
## 17: 0.02575        5     0.2227 b44c8060-c330-4710-b5d1-6ec497739774 &lt;list[2]&gt;
## 18: 0.05050        1     0.2500 3abf0b56-3337-405e-b000-026455a5b016 &lt;list[2]&gt;
## 19: 0.02575        8     0.2227 93120580-347a-4dd9-9e91-635f478b2cf4 &lt;list[2]&gt;
## 20: 0.07525        5     0.2500 6e241d72-2726-4ae2-95d2-5be35c9bb030 &lt;list[2]&gt;
##               timestamp batch_nr
##  1: 2020-10-26 13:37:03        1
##  2: 2020-10-26 13:37:03        2
##  3: 2020-10-26 13:37:03        3
##  4: 2020-10-26 13:37:03        4
##  5: 2020-10-26 13:37:03        5
##  6: 2020-10-26 13:37:03        6
##  7: 2020-10-26 13:37:04        7
##  8: 2020-10-26 13:37:04        8
##  9: 2020-10-26 13:37:04        9
## 10: 2020-10-26 13:37:04       10
## 11: 2020-10-26 13:37:04       11
## 12: 2020-10-26 13:37:04       12
## 13: 2020-10-26 13:37:04       13
## 14: 2020-10-26 13:37:04       14
## 15: 2020-10-26 13:37:04       15
## 16: 2020-10-26 13:37:04       16
## 17: 2020-10-26 13:37:05       17
## 18: 2020-10-26 13:37:05       18
## 19: 2020-10-26 13:37:05       19
## 20: 2020-10-26 13:37:05       20</code></pre>
<p>In sum, the grid search evaluated 20/25 different configurations of the grid in a random order before the <a href="https://bbotk.mlr-org.com/reference/Terminator.html"><code>Terminator</code></a> stopped the tuning.</p>
<p>The associated resampling iterations can be accessed in the <a href="https://mlr3.mlr-org.com/reference/BenchmarkResult.html"><code>BenchmarkResult</code></a>:</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="tuning.html#cb197-1"></a>instance<span class="op">$</span>archive<span class="op">$</span>benchmark_result<span class="op">$</span>data</span></code></pre></div>
<pre><code>## &lt;ResultData&gt;
##   Public:
##     as_data_table: function (view = NULL, reassemble_learners = TRUE, convert_predictions = TRUE, 
##     clone: function (deep = FALSE) 
##     combine: function (rdata) 
##     data: list
##     initialize: function (data = NULL) 
##     iterations: function (view = NULL) 
##     learners: function (view = NULL, states = TRUE, reassemble = TRUE) 
##     logs: function (view = NULL, condition) 
##     prediction: function (view = NULL, predict_sets = &quot;test&quot;) 
##     predictions: function (view = NULL, predict_sets = &quot;test&quot;) 
##     resamplings: function (view = NULL) 
##     sweep: function () 
##     task_type: active binding
##     tasks: function (view = NULL, reassemble = TRUE) 
##     uhashes: function (view = NULL) 
##   Private:
##     deep_clone: function (name, value) 
##     get_view_index: function (view)</code></pre>
<p>The <code>uhash</code> column links the resampling iterations to the evaluated configurations stored in <code>instance$archive$data()</code>. This allows e.g. to score the included <a href="https://mlr3.mlr-org.com/reference/ResampleResult.html"><code>ResampleResult</code></a>s on a different measure.</p>
<p>Now the optimized hyperparameters can take the previously created <a href="https://mlr3.mlr-org.com/reference/Learner.html"><code>Learner</code></a>, set the returned hyperparameters and train it on the full dataset.</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="tuning.html#cb199-1"></a>learner<span class="op">$</span>param_set<span class="op">$</span>values =<span class="st"> </span>instance<span class="op">$</span>result_learner_param_vals</span>
<span id="cb199-2"><a href="tuning.html#cb199-2"></a>learner<span class="op">$</span><span class="kw">train</span>(task)</span></code></pre></div>
<p>The trained model can now be used to make a prediction on external data.
Note that predicting on observations present in the <code>task</code>, should be avoided.
The model has seen these observations already during tuning and therefore results would be statistically biased.
Hence, the resulting performance measure would be over-optimistic.
Instead, to get statistically unbiased performance estimates for the current task, <a href="#nested-resamling">nested resampling</a> is required.</p>
</div>
<div id="autotuner" class="section level3">
<h3><span class="header-section-number">3.1.4</span> Automating the Tuning</h3>
<p>The <a href="https://mlr3tuning.mlr-org.com/reference/AutoTuner.html"><code>AutoTuner</code></a> wraps a learner and augments it with an automatic tuning for a given set of hyperparameters.
Because the <a href="https://mlr3tuning.mlr-org.com/reference/AutoTuner.html"><code>AutoTuner</code></a> itself inherits from the <a href="https://mlr3.mlr-org.com/reference/Learner.html"><code>Learner</code></a> base class, it can be used like any other learner.
Analogously to the previous subsection, a new classification tree learner is created.
This classification tree learner automatically tunes the parameters <code>cp</code> and <code>minsplit</code> using an inner resampling (holdout).
We create a terminator which allows 10 evaluations, and use a simple random search as tuning algorithm:</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="tuning.html#cb200-1"></a><span class="kw">library</span>(<span class="st">&quot;paradox&quot;</span>)</span>
<span id="cb200-2"><a href="tuning.html#cb200-2"></a><span class="kw">library</span>(<span class="st">&quot;mlr3tuning&quot;</span>)</span>
<span id="cb200-3"><a href="tuning.html#cb200-3"></a></span>
<span id="cb200-4"><a href="tuning.html#cb200-4"></a>learner =<span class="st"> </span><span class="kw">lrn</span>(<span class="st">&quot;classif.rpart&quot;</span>)</span>
<span id="cb200-5"><a href="tuning.html#cb200-5"></a>tune_ps =<span class="st"> </span>ParamSet<span class="op">$</span><span class="kw">new</span>(<span class="kw">list</span>(</span>
<span id="cb200-6"><a href="tuning.html#cb200-6"></a>  ParamDbl<span class="op">$</span><span class="kw">new</span>(<span class="st">&quot;cp&quot;</span>, <span class="dt">lower =</span> <span class="fl">0.001</span>, <span class="dt">upper =</span> <span class="fl">0.1</span>),</span>
<span id="cb200-7"><a href="tuning.html#cb200-7"></a>  ParamInt<span class="op">$</span><span class="kw">new</span>(<span class="st">&quot;minsplit&quot;</span>, <span class="dt">lower =</span> <span class="dv">1</span>, <span class="dt">upper =</span> <span class="dv">10</span>)</span>
<span id="cb200-8"><a href="tuning.html#cb200-8"></a>))</span>
<span id="cb200-9"><a href="tuning.html#cb200-9"></a>terminator =<span class="st"> </span><span class="kw">trm</span>(<span class="st">&quot;evals&quot;</span>, <span class="dt">n_evals =</span> <span class="dv">10</span>)</span>
<span id="cb200-10"><a href="tuning.html#cb200-10"></a>tuner =<span class="st"> </span><span class="kw">tnr</span>(<span class="st">&quot;random_search&quot;</span>)</span>
<span id="cb200-11"><a href="tuning.html#cb200-11"></a></span>
<span id="cb200-12"><a href="tuning.html#cb200-12"></a>at =<span class="st"> </span>AutoTuner<span class="op">$</span><span class="kw">new</span>(</span>
<span id="cb200-13"><a href="tuning.html#cb200-13"></a>  <span class="dt">learner =</span> learner,</span>
<span id="cb200-14"><a href="tuning.html#cb200-14"></a>  <span class="dt">resampling =</span> <span class="kw">rsmp</span>(<span class="st">&quot;holdout&quot;</span>),</span>
<span id="cb200-15"><a href="tuning.html#cb200-15"></a>  <span class="dt">measure =</span> <span class="kw">msr</span>(<span class="st">&quot;classif.ce&quot;</span>),</span>
<span id="cb200-16"><a href="tuning.html#cb200-16"></a>  <span class="dt">search_space =</span> tune_ps,</span>
<span id="cb200-17"><a href="tuning.html#cb200-17"></a>  <span class="dt">terminator =</span> terminator,</span>
<span id="cb200-18"><a href="tuning.html#cb200-18"></a>  <span class="dt">tuner =</span> tuner</span>
<span id="cb200-19"><a href="tuning.html#cb200-19"></a>)</span>
<span id="cb200-20"><a href="tuning.html#cb200-20"></a>at</span></code></pre></div>
<pre><code>## &lt;AutoTuner:classif.rpart.tuned&gt;
## * Model: -
## * Parameters: xval=0
## * Packages: rpart
## * Predict Type: response
## * Feature types: logical, integer, numeric, factor, ordered
## * Properties: importance, missings, multiclass, selected_features,
##   twoclass, weights</code></pre>
<p>We can now use the learner like any other learner, calling the <code>$train()</code> and <code>$predict()</code> method.
This time however, we pass it to <a href="https://mlr3.mlr-org.com/reference/benchmark.html"><code>benchmark()</code></a> to compare the tuner to a classification tree without tuning.
This way, the <a href="https://mlr3tuning.mlr-org.com/reference/AutoTuner.html"><code>AutoTuner</code></a> will do its resampling for tuning on the training set of the respective split of the outer resampling.
The learner then undertakes predictions using the test set of the outer resampling.
This yields unbiased performance measures, as the observations in the test set have not been used during tuning or fitting of the respective learner.
This is called <a href="nested-resampling.html#nested-resampling">nested resampling</a>.</p>
<p>To compare the tuned learner with the learner that uses default values, we can use <a href="https://mlr3.mlr-org.com/reference/benchmark.html"><code>benchmark()</code></a>:</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="tuning.html#cb202-1"></a>grid =<span class="st"> </span><span class="kw">benchmark_grid</span>(</span>
<span id="cb202-2"><a href="tuning.html#cb202-2"></a>  <span class="dt">task =</span> <span class="kw">tsk</span>(<span class="st">&quot;pima&quot;</span>),</span>
<span id="cb202-3"><a href="tuning.html#cb202-3"></a>  <span class="dt">learner =</span> <span class="kw">list</span>(at, <span class="kw">lrn</span>(<span class="st">&quot;classif.rpart&quot;</span>)),</span>
<span id="cb202-4"><a href="tuning.html#cb202-4"></a>  <span class="dt">resampling =</span> <span class="kw">rsmp</span>(<span class="st">&quot;cv&quot;</span>, <span class="dt">folds =</span> <span class="dv">3</span>)</span>
<span id="cb202-5"><a href="tuning.html#cb202-5"></a>)</span>
<span id="cb202-6"><a href="tuning.html#cb202-6"></a></span>
<span id="cb202-7"><a href="tuning.html#cb202-7"></a><span class="co"># avoid console output from mlr3tuning</span></span>
<span id="cb202-8"><a href="tuning.html#cb202-8"></a>logger =<span class="st"> </span>lgr<span class="op">::</span><span class="kw">get_logger</span>(<span class="st">&quot;bbotk&quot;</span>)</span>
<span id="cb202-9"><a href="tuning.html#cb202-9"></a>logger<span class="op">$</span><span class="kw">set_threshold</span>(<span class="st">&quot;warn&quot;</span>)</span>
<span id="cb202-10"><a href="tuning.html#cb202-10"></a></span>
<span id="cb202-11"><a href="tuning.html#cb202-11"></a>bmr =<span class="st"> </span><span class="kw">benchmark</span>(grid)</span>
<span id="cb202-12"><a href="tuning.html#cb202-12"></a>bmr<span class="op">$</span><span class="kw">aggregate</span>(<span class="kw">msrs</span>(<span class="kw">c</span>(<span class="st">&quot;classif.ce&quot;</span>, <span class="st">&quot;time_train&quot;</span>)))</span></code></pre></div>
<pre><code>##    nr      resample_result task_id          learner_id resampling_id iters
## 1:  1 &lt;ResampleResult[21]&gt;    pima classif.rpart.tuned            cv     3
## 2:  2 &lt;ResampleResult[21]&gt;    pima       classif.rpart            cv     3
##    classif.ce time_train
## 1:     0.2461          0
## 2:     0.2604          0</code></pre>
<p>Note that we do not expect any differences compared to the non-tuned approach for multiple reasons:</p>
<ul>
<li>the task is too easy</li>
<li>the task is rather small, and thus prone to overfitting</li>
<li>the tuning budget (10 evaluations) is small</li>
<li><a href="https://cran.r-project.org/package=rpart">rpart</a> does not benefit that much from tuning</li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-bergstra2012">
<p>Bergstra, James, and Yoshua Bengio. 2012. “Random Search for Hyper-Parameter Optimization.” <em>J. Mach. Learn. Res.</em> 13: 281–305.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="optimization.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="fs.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mlr-org/mlr3book/edit/master/bookdown/03-optimization-tuning.Rmd",
"text": "Edit this chapter"
},
"history": {
"link": "https://github.com/mlr-org/mlr3book/commits/master/03-optimization-tuning.Rmd",
"text": "Edit history"
},
"view": {
"link": null,
"text": null
},
"download": [["mlr3book.pdf", "PDF"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
